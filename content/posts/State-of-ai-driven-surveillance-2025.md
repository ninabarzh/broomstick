---
title: 'The AI-augmented Panopticon: Surveillance in 2025'
date: 2025-05-18T12:00:00.000Z
draft: false
tags:
  - surveillance
  - ai
  - panopticon
---

In 2025, the financial sector continues its courtship with generative AI, hoping it will finally make compliance less 
of a bureaucratic slog. According to Global Relay's *State of AI in Surveillance Report 2025*, attitudes are thawing: 
there’s been a 19% drop in firms reluctant to implement AI. Apparently, nothing eases doubts like the promise of 
automated paperwork and plausible deniability. Still, not all is rosy. Explainability remains elusive, regulators 
are breathing down necks, and integration often resembles a Frankensteinian patchwork. Innovation, it seems, 
comes with a compliance hangover.

Beyond finance, AI is now the darling of physical security, spotting odd behaviour, identifying faces in crowds, and 
predicting crimes before they happen (or not). German defence start-up Helsing, for example, has plans to release a 
swarm of underwater drones with “advanced AI” to boost naval surveillance. Because nothing says peace of mind like 
the quiet hum of a robot lurking in the deep.

![](/images/panopticon2025.png#center)

## Convergence of physical and digital monitoring

Surveillance has gone from watching CCTV tapes in a dingy room to something called “visual intelligence,” where 
AI analyses footage in real-time for anything resembling trouble, or, occasionally, a dog mistaken for a burglar. 
This AI-augmented vision is increasingly tied into the grand convergence of IT, OT, and security systems, because if 
you’re going to be vulnerable, you might as well be efficiently vulnerable.

The UK's Royal Navy is piloting Project Cabot, which aims to have uncrewed undersea vehicles communicate with 
AI-powered acoustic systems. A noble endeavour, if the goal is to create a sentient navy that pings back.

## AI surveillance in 2025: A global panorama

Surveillance in 2025 is more pervasive, more automated, and far more likely to call you suspicious for looking at 
your phone the wrong way. States and corporations alike are racing to squeeze every drop of insight from your data, 
sometimes in the name of safety, other times for more creative interpretations of “national interest.” The boundary 
between defence and intrusion continues to blur, and the average citizen finds themselves in the awkward position 
of being simultaneously protected and targeted.

**Note:** The following is hardly a complete list. Global surveillance programmes are as widespread as they are 
hush-hush, and many remain hidden under layers of classification or charming euphemisms like “public safety 
initiative.” This curated selection offers a glimpse into the more transparent corners of the global surveillance 
theatre.

### Europe

**United Kingdom**  

In true dystopian fashion, the UK’s Ministry of Justice uses AI to profile over 1,300 individuals daily to determine 
their risk of reoffending. The next phase? A system to predict potential murderers. What could possibly go wrong?

**Belgium** 

A recent report has dared to suggest that predictive policing might not be entirely ethical, particularly when it 
relies on dodgy databases and sociological guesswork. Brussels, ever the voice of reason, is considering a ban.

**Hungary**

Not content with just banning Pride marches, Hungary has weaponised facial recognition to identify and penalise 
participants. It’s privacy invasion meets political repression, with a dash of algorithmic bias.

### Middle East

**Saudi Arabia** 

NEOM, the futuristic $8.8 trillion megacity, promises jetpacks, robot servants, and, of course, total surveillance. 
Reports of forced displacements and up to 21,000 worker deaths have somewhat dulled the shine, though the PR 
brochures remain top notch.

**Iran**

Iranian authorities have turned AI into an instrument of suppression, employing facial recognition and geolocation 
to crack down on protest. Following Mahsa Amini’s death, over 20,000 were arrested, proving once again that 
authoritarianism scales well with machine learning.

### Asia

**China**

China remains the gold standard of techno-authoritarianism. AI surveillance is omnipresent, especially in Xinjiang, 
and its export to other regimes makes Orwell look quaint. Exporting digital repression: now available on Belt and Road.

**India**

India’s surveillance sector is booming. AI tools are deployed with gusto, even as spyware scandals, Supreme Court 
probes, and human rights concerns pile up like unread privacy policies.

### Africa

**South Africa**

Gauteng province has partnered with Vumacam to install over 6,000 cameras loaded with AI capabilities like licence 
plate recognition and behaviour detection. Naturally, there’s no real regulation for this sort of thing, but rest 
assured, someone somewhere is watching.

**Uganda**

During the 2021 elections, Uganda demonstrated the dark art of algorithmic suppression by using AI to monitor 
social media and stifle dissent. Proof that surveillance tech, once acquired, rarely sits idle.

### South America

**Argentina**

Argentina has launched an AI crime prediction unit, apparently inspired by *Minority Report* and a generous 
interpretation of due process. It uses historical data to divine future misdeeds, bias included at no extra charge.

**Brazil** 

Brazil’s surveillance infrastructure is powered by algorithms that trawl state databases with minimal oversight. 
A dream for statisticians, a nightmare for civil liberties.

### Oceania

**New Zealand**  

NZ police teamed up with SaferCities to roll out the vGRID platform: a network of thousands of cameras accessible 
from officers’ phones. During COVID-19, police reportedly flagged cars as “stolen” to bypass lockdown rules. 
Creative, certainly. Legal? Not so much.

## Privacy vs. security tensions

[Federated learning](https://indigo.tymyrddin.dev/docs/landscape/hybrid.html#federated-learning) and privacy-preserving 
AI are all the rage in marketing decks. Apple champions on-device processing, which is lovely, until you realise your 
phone still knows more about you than your best mate. 

The US, meanwhile, warns of AI-enabled disinformation, though it’s unclear if the concern is ethical or competitive.

And then there’s Meta’s AI-powered therapy bots. What could be more reassuring than baring your soul to a chatbot 
owned by the world's largest advertising firm?

## Global power shifts

Surveillance is no longer just about keeping an eye on things, it’s about who controls the eye. 
The battlefield now spans land, sea, space, and that murky zone where your toaster knows more than you do. And the 
AI arms race shows no sign of slowing down, especially with authoritarian states writing the rulebook as they go.

## Resources

*  Mozilla Foundation. VCs Will Face Their Privacy Reckoning in 2025. Mozilla Foundation, 2025. https://foundation.mozilla.org/en/what-we-fund/programs/vcs-will-face-their-privacy-reckoning-in-2025/
*  Amnesty International. Governments and Corporate Actors Are Breaking International Law With Impunity. Amnesty International, April 2024. https://www.amnesty.org/en/latest/news/2024/04/amnesty-international-sounds-alarm-international-law-flagrant-rule-breaking-governments-corporate-actors/
*  Electronic Frontier Foundation (EFF). New Report Provides Guidance to Protect Human Rights Amid Government Surveillance. EFF, October 2024. https://www.eff.org/deeplinks/2024/10/new-eff-report-provides-guidance-ensure-human-rights-are-protected-amid-government
*  Statewatch. Predictive Policing and Data Profiling in the EU. Statewatch, April 2025. https://www.statewatch.org/news/2025/april/
*  Wikipedia. Hungarian Anti-LGBTQ Law. Wikimedia Foundation. https://en.wikipedia.org/wiki/Hungarian_anti-LGBTQ_law
*  Statewatch. UK Ministry of Justice Experiments with AI Profiling in Parole Decisions. Statewatch, 2025. https://www.statewatch.org/news/2025/april/
*  Wikipedia. Mass Surveillance in Iran. Wikimedia Foundation. https://en.wikipedia.org/wiki/Mass_surveillance_in_Iran
*  The Sun. Saudi NEOM Megacity Raises Human Rights Concerns Amid Surveillance Plans. The Sun. https://www.thesun.co.uk/news/35004897/saudi-neom-megacity-project/
*  Wikipedia. Techno-authoritarianism. Wikimedia Foundation. https://en.wikipedia.org/wiki/Techno-authoritarianism
*  Mozilla Foundation. VCs Will Face Their Privacy Reckoning in 2025 (includes Indian spyware section). https://foundation.mozilla.org/en/what-we-fund/programs/vcs-will-face-their-privacy-reckoning-in-2025/
*  Mozilla Foundation. South Africa’s AI-Driven Urban Surveillance Network (Vumacam). https://foundation.mozilla.org/en/what-we-fund/programs/vcs-will-face-their-privacy-reckoning-in-2025/
*  Amnesty International Thailand. Uganda: Protest Surveillance and Human Rights Abuses during Elections. Amnesty International Thailand. https://www.amnesty.or.th/en/latest/news/1251/
*  The Guardian. Argentina's AI System for Predicting Future Crimes Raises Rights Concerns. The Guardian, August 2024. https://www.theguardian.com/world/article/2024/aug/01/argentina-ai-predicting-future-crimes-citizen-rights
*  Amnesty International Thailand. Brazil's Expanding Algorithmic Governance Poses Human Rights Risks. Amnesty International Thailand. https://www.amnesty.or.th/en/latest/news/1251/
*  Wikipedia. Mass Surveillance in New Zealand. Wikimedia Foundation. https://en.wikipedia.org/wiki/Mass_surveillance_in_New_Zealand

![](/images/compliance-dept.png#center)